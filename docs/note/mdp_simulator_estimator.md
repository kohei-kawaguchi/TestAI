# AIをRAとして活用する：モンテカルロシミュレーションと構造推定の実装事例

## はじめに

前回の記事では、マルコフ意思決定過程（MDP）の最適方策を導出する「ソルバー」の実装をAIに依頼しました。今回はその続編として、**モンテカルロシミュレーション**と**構造推定（逆強化学習）**を実装し、完全な計算パイプラインを構築します。

この3つのステップ——**solve（解く）→ simulate（シミュレート）→ estimate（推定する）**——を連携させ、最終的に**パラメータを正確に回復できることを確認する**のが本プロジェクトの目標です。これは単なる実装の検証ではなく、**モデルの中核機能が正しいことの究極の証明**になります。

## パラメータ回復は究極の検証

構造推定の文脈では、**パラメータ回復（parameter recovery）**が最も厳密な検証方法とされています。

### なぜパラメータ回復が重要か

通常の単体テストは「この関数は正しく動くか」を検証します。しかし、それだけではモデル全体が正しいとは言えません。個々の関数が正しくても、それらの組み合わせ方が間違っていれば、誤った結果を出します。

パラメータ回復は、以下のすべてが正しいことを同時に証明します：

1. **ソルバーが正しい均衡を計算している**
   - Bellman方程式を正しく実装
   - 価値関数が収束している
   - 最適方策が理論的予測と整合

2. **シミュレーターが正しい意思決定ルールを実装している**
   - 価値関数から選択確率を正しく導出
   - 状態遷移を正しく実装
   - モンテカルロ標本が理論分布と一致

3. **推定器が正しくモデルを反転している**
   - 尤度関数が正しく定義されている
   - 最適化が収束している
   - 推定値が真のパラメータに一致

**重要なのは、この3つすべてが同時に成立して初めて、パラメータが正確に回復される**ということです。どこか1つでも間違っていれば、推定値はズレます。つまり、パラメータ回復の成功は、計算パイプライン全体が正しいことの証明なのです。

### 一度では成功しない

この検証が難しいのは、**最初の試行でパラメータ回復が成功することはほぼない**という点です。

- ソルバーのバグ → 誤った価値関数 → 誤ったシミュレーションデータ → 誤った推定値
- シミュレーターのバグ → モデルと整合しないデータ → バイアスのある推定値
- 推定器のバグ → 正しいデータからでも誤った推定値

デバッグには、どのコンポーネントが問題なのかを切り分ける必要があります。各コンポーネントを独立に検証してから統合する、という段階的アプローチが不可欠です。

今回の実装でも、いくつかのバグを経て、最終的に相対誤差1%未満でパラメータを回復できることを確認しました。この成功は、モデル実装が正しいことの強力な証拠です。

## データ・設定・関数のパイプライン管理

3つのステップ（ソルバー、シミュレーター、推定器）を連携させるには、**データ、設定、関数を一貫して管理する**仕組みが必要です。

### 設定をデータとして扱う

本プロジェクトでは、**「設定をデータとして扱う」**という原則を徹底しています。

従来のアプローチでは、パラメータをコード内にハードコードし、異なるスクリプトで同じパラメータを何度も定義していました。これでは、パラメータを変更するときに複数箇所を修正する必要があり、変更の整合性が保証されません。

本プロジェクトでは、以下の方法でこの問題を解決しています：

1. **単一の設定モジュール（`mdp_utils/config.py`）**
   - すべてのパラメータを一箇所で定義
   - `get_solver_config()`、`get_comparative_statics()` などの関数で取得
   - ソルバー、シミュレーター、推定器すべてが同じ設定を参照

2. **設定を結果と一緒に保存**
   - ソルバーは `output/solve_mdp/config.json` に設定を保存
   - シミュレーターは `output/simulate_mdp/config.json` に設定を保存
   - 推定器は保存された設定を読み込んで検証

3. **設定の整合性を自動検証**
   ```python
   # シミュレーターで設定を読み込む
   with open('output/solve_mdp/config.json', 'r') as f:
       loaded_config = json.load(f)

   # 現在の設定と一致するか確認
   current_config = get_solver_config()
   assert loaded_config['beta'] == current_config['beta'], \
       "設定が一致しません！"
   ```

この方法により、設定の不一致が原因のバグを自動的に検出できます。推定器が間違った設定で動いていた、というミスは起こりえません。

### DRY原則の徹底

**DRY（Don't Repeat Yourself）原則**も重要です。同じ計算を複数箇所で実装すると、一箇所を修正したときに他の箇所も修正し忘れ、バグの温床になります。

本プロジェクトでは、以下の関数を共有モジュール（`mdp_utils/`）に集約しています：

- **報酬関数（`reward(s, a, beta)`）**：ソルバー、シミュレーター、推定器すべてが同じ実装を使用
- **状態遷移（`next_state(s, a, gamma)`）**：シミュレーターと推定器で共有
- **価値関数の可視化（`plot_value_functions()`）**：3つすべてのステップで使用

これにより、例えば報酬関数の定義を変更する場合、`mdp_utils/core.py` の1箇所を修正するだけで、すべてのステップに変更が反映されます。

### パイプラインの設計

データの流れは以下のようになります：

1. **ソルバー（`solve_mdp.qmd`）**
   - 入力：設定（`config.py`）
   - 出力：訓練済みニューラルネットワーク（`.pt`ファイル）、設定（`config.json`）

2. **シミュレーター（`simulate_mdp.qmd`）**
   - 入力：ソルバーの出力（ネットワーク＋設定）
   - 出力：シミュレーションデータ（状態、行動、報酬の時系列）、設定（`config.json`）

3. **推定器（`estimate_mdp.qmd`）**
   - 入力：シミュレーターの出力（データ＋設定）
   - 出力：推定されたパラメータ、推定された価値関数

各ステップは独立して実行可能であり、前のステップの出力を読み込んで次のステップに進みます。この設計により、デバッグが容易になり、任意のステップだけを再実行できます。

## 実用的なアルゴリズム選択

推定器の実装において、**理論的に洗練されたアルゴリズム**と**実用的に機能するアルゴリズム**は必ずしも一致しません。

### 試行錯誤の過程

今回の実装では、3つのアルゴリズムを試しました：

1. **CCP（Conditional Choice Probability）二段階推定法**
   - 理論的には優雅：選択確率をニューラルネットで推定 → Bellman方程式を反転
   - 問題：2つの近似誤差が累積、単調性制約の実装が困難
   - 結果：**採用せず**（複雑すぎ、不安定）

2. **NFXP（Nested Fixed Point）+ L-BFGS-B最適化**
   - 理論的には正しい：尤度を直接最大化
   - 問題：各評価でMDPを解く必要があり、最適化が数時間停止
   - 結果：**採用せず**（研究イテレーションには遅すぎる）

3. **NFXP + グリッドサーチ**
   - 実用的：パラメータ空間を明示的に探索
   - 利点：尤度曲面を可視化、大域最適が保証される
   - 結果：**採用**（1次元パラメータには十分実用的）

### 実用性を優先する

重要な教訓は、**最もシンプルで機能するアプローチを選ぶ**ことです。

グリッドサーチが好ましいのは以下の場合です：
- 低次元のパラメータ空間（1〜2次元）
- 可視化が研究にとって価値がある
- 透明性が重要
- 計算コストが許容範囲

最適化が好ましいのは以下の場合です：
- 高次元のパラメータ空間
- グリッドサーチが計算量的に不可能
- 高精度な最適値が必要

今回は1次元パラメータ（β）の推定だったため、グリッドサーチで十分でした。20点のグリッドで約10分で完了し、尤度曲面を可視化することで、推定の妥当性を視覚的に確認できました。

## 本番実行前の診断

推定を本番実行する前に、**診断的検証**を行うことが重要です。

### 診断ワークフロー

1. **尤度プロファイルを真のパラメータ周辺で描画**
   - 真のパラメータ β=0.5 の周辺で尤度を計算
   - グラフで可視化

2. **視覚的チェック**
   - 尤度は滑らかか？
   - 最大値は真のパラメータにあるか？
   - 局所最適が存在するか？
   - 曲面は凹か？

3. **本番推定を実行**
   - 診断が問題なければ、全グリッドで推定

4. **結果の検証**
   - 推定パラメータ vs 真のパラメータ
   - 推定された価値関数 vs 真の価値関数
   - 推定された選択確率 vs 真の選択確率
   - 推定誤差が小さいか（相対誤差 < 1%）

この診断により、本番実行前に重大な問題を発見できます。例えば、真のパラメータで尤度が最大にならなければ、シミュレーターか推定器にバグがあることが分かります。

### 実際の結果

今回の実装では、以下の結果が得られました：

- **推定されたβ**：0.500（真の値：0.500、相対誤差：0.0%）
- **価値関数の視覚的一致**：推定された価値関数が真の価値関数とほぼ完全に重なる
- **選択確率の一致**：推定された選択確率が真の選択確率と整合

これは、ソルバー、シミュレーター、推定器すべてが正しく実装されていることの証明です。

## モンテカルロシミュレーションの実装

シミュレーターは、ソルバーが出力した価値関数を使って、**エージェントの意思決定プロセスをモンテカルロ法でシミュレート**します。

### シミュレーションの流れ

1. **初期状態をランダムに設定**
   - 状態空間 [0, 10] から一様分布でサンプリング

2. **各時点で意思決定をシミュレート**
   - 価値関数 V(s, a=0) と V(s, a=1) をニューラルネットワークで評価
   - Type-I極値分布のショックを加えて確率的に行動を選択
   - 選択確率：P(a=1|s) = exp(V(s,1)) / [exp(V(s,0)) + exp(V(s,1))]

3. **次の状態に遷移**
   - 状態遷移：s' = (1-γ)s + a
   - 報酬を記録：r(s,a) = β·log(1+s) - a

4. **T期間繰り返す**
   - 各エージェントの完全な経路（状態、行動、報酬）を記録

### 複数エージェントのシミュレーション

構造推定では、十分なサンプルサイズが必要です。今回は以下の設定でシミュレーションを行いました：

- **エージェント数**：N=1000
- **時間期間**：T=100
- **総観測数**：N×T = 100,000

これにより、統計的に安定した推定が可能になります。

### シミュレーションの検証

シミュレーションが正しいことを確認するため、以下をチェックします：

- **選択確率の分布**：理論的な選択確率と標本比率が一致するか
- **状態の定常分布**：長期的に状態がどのように分布するか
- **報酬の時系列**：経済学的に妥当なパターンか

これらをQuartoレポート（`simulate_mdp.html`）で可視化し、シミュレーションの妥当性を確認します。

## 構造推定：逆問題としての推定

推定器は、シミュレーションの逆問題を解きます。つまり、**観測されたデータから、それを生成したパラメータを逆算**します。

### Nested Fixed Point（NFXP）アルゴリズム

構造推定では、NFXP法が標準的なアプローチです：

1. **パラメータ候補（β）を選ぶ**

2. **そのパラメータでMDPを解く**
   - ソルバーと同じ方法で価値関数を計算
   - これが「固定点（Fixed Point）」

3. **尤度を計算**
   - 観測された各 (s, a) のペアに対して
   - 選択確率 P(a|s; β) を計算
   - 対数尤度を合計：ℓ(β) = Σ log P(a|s; β)

4. **尤度を最大化するβを探す**
   - グリッドサーチまたは最適化

### グリッドサーチによる実装

今回は、β ∈ [0.3, 0.7] の範囲を20点のグリッドで探索しました：

```python
beta_grid = np.linspace(0.3, 0.7, 20)
likelihoods = []

for beta in beta_grid:
    # このβでMDPを解く
    v0, v1 = solve_mdp(beta=beta, gamma=gamma_true)

    # 尤度を計算
    log_likelihood = compute_likelihood(data, v0, v1)
    likelihoods.append(log_likelihood)

# 尤度が最大となるβを選ぶ
beta_hat = beta_grid[np.argmax(likelihoods)]
```

この方法の利点は、尤度曲面を完全に可視化できることです。尤度がβに対して滑らかに変化し、真のパラメータで最大となることを視覚的に確認できます。

### 共有関数の再利用

重要なのは、**推定器がソルバーと全く同じ関数を使う**ことです。

- 報酬関数：`mdp_utils.core.reward()`
- 状態遷移：`mdp_utils.core.next_state()`
- Bellmanオペレータ：`mdp_utils.core.bellman_operator()`

これにより、推定器は「ソルバーが使ったのと全く同じモデル」でパラメータを推定します。実装の不整合によるバグは原理的に発生しません。

## 会話履歴の記録と学び

前回同様、AIとの会話履歴を詳細に記録し、[`docs/conversation/mdp_simulator_estimator_conversation_transcript.md`](../../conversation/mdp_simulator_estimator_conversation_transcript.md)として公開しています。

今回の会話履歴には、以下のような学びが含まれています：

- **「ファイルを作る」≠「内容を書く」**：ユーザーが明示的に「内容を書いて」と言うまで待つ
- **設定の不一致を早期に検出**：各ステップで設定を検証するコードの重要性
- **アルゴリズムの実用的選択**：理論的な洗練さより、実際に動くことを優先
- **診断の重要性**：本番実行前に小規模な検証を行う

会話履歴は、単なる記録以上の価値があります。なぜその選択をしたのか、どこでつまずいたのか、どうやって解決したのか——これらの情報は、同様のプロジェクトに取り組む際の貴重な参考資料になります。

また、会話履歴とGitコミット履歴を事後的にAIに評価させることで、自分の監督の仕方を改善できます。「この段階でもっと早く確認すべきだった」「この指示は曖昧すぎた」といったフィードバックを得ることができます。

## まとめ：完全なパイプラインの構築

本実装事例は、**solve → simulate → estimate → recover** という完全な計算パイプラインをAIに実装させる方法論を示しました。

### 核心的な原則

1. **パラメータ回復は究極の検証**
   パラメータを正確に回復できることは、ソルバー、シミュレーター、推定器すべてが正しいことの証明。単体テストだけでは不十分。

2. **設定をデータとして扱う**
   設定を結果と一緒に保存し、各ステップで読み込んで検証する。設定の不一致を自動検出することで、バグを防ぐ。

3. **DRY原則の徹底**
   報酬関数、状態遷移、可視化などを共有モジュールに集約。一箇所の変更がすべてのステップに反映される。

4. **実用的なアルゴリズム選択**
   理論的な洗練さより、実際に動くことを優先。グリッドサーチは低次元パラメータに対して十分実用的で、可視化による検証が可能。

5. **診断的検証の重要性**
   本番実行前に小規模な検証を行う。尤度プロファイルを可視化し、真のパラメータで最大となることを確認。

6. **完全な会話履歴の記録**
   再現性のためだけでなく、ノウハウの共有と自己改善のツールとして。事後的にAIに評価させることで監督の仕方を改善できる。

### より複雑な問題への拡張

今回のMDPは単純なモデルでしたが、同じ方法論はより複雑な問題にも適用できます：

- **多次元パラメータ**：複数のパラメータを同時推定
- **異質性のあるエージェント**：タイプ別のパラメータ推定
- **不完備情報**：信念の更新を含むモデル
- **ゲーム理論的均衡**：複数プレイヤーの戦略的相互作用

コンセプトは同じです。solve → simulate → estimate → recoverのパイプラインを構築し、各ステップで設定と関数を共有し、最終的にパラメータ回復で検証する。

### 実装の全公開

詳細な会話履歴、すべてのコード、レンダリングされたHTMLレポートは[GitHubリポジトリ](https://github.com/kohei-kawaguchi/TestAI)で公開しています。

特に、以下のファイルは完全な計算パイプラインを理解する上で有用です：

- [`docs/conversation/mdp_simulator_estimator_conversation_transcript.md`](../../conversation/mdp_simulator_estimator_conversation_transcript.md)：完全な会話履歴、各段階での判断基準
- [`scripts/solve_mdp/solve_mdp.html`](../../scripts/solve_mdp/solve_mdp.html)：ソルバーの実装とテスト
- [`scripts/simulate_mdp/simulate_mdp.html`](../../scripts/simulate_mdp/simulate_mdp.html)：シミュレーターの実装と検証
- [`scripts/estimate_mdp/estimate_mdp.html`](../../scripts/estimate_mdp/estimate_mdp.html)：推定器の実装とパラメータ回復

これらを参照することで、同様のプロジェクトに取り組む際の具体的な指針が得られます。
