# AIをRAとして活用する：パラメータ回復による最も包括的な検証

## はじめに

前回の記事では、マルコフ意思決定過程（MDP）の均衡計算をAIに実装させました。今回はその続編として、**シミュレーションと構造推定**を加えた完全なパイプラインを構築します。

重要なのは、**solve（解く）→ simulate（シミュレート）→ estimate（推定する）→ recover（回復する）**という一連の流れを完成させることです。真のパラメータでデータを生成し、それを推定し、元のパラメータを正確に回復できることを確認する——これは**実装が正しいことの最も包括的な検証**になります。

## パラメータ回復は最も包括的な検証

構造推定では、**パラメータ回復（parameter recovery）**が最も厳密な検証方法です。

### なぜパラメータ回復が重要か

単体テストは「この関数は正しく動くか」を検証します。比較静学は「パラメータを変えたとき結果が理論と整合するか」を検証します。しかし、これらだけでは不十分です。

パラメータ回復は、**システム全体のend-to-end検証**です。真のパラメータでモデルを解き、データを生成し、そのデータから元のパラメータを推定する——この一連の流れが正しく機能して初めて、パラメータが正確に回復されます。

**どこか1つでもバグがあれば、パラメータは回復されません。**

- ソルバーのバグ → 誤った均衡 → 誤ったデータ → 誤った推定値
- シミュレーターのバグ → モデルと整合しないデータ → バイアスのある推定値
- 推定器のバグ → 正しいデータからでも誤った推定値

つまり、パラメータ回復の成功は、**ソルバー、シミュレーター、推定器すべてが正しく実装され、整合的に動いている**ことの証明です。

### 一度では成功しない

重要な点は、**パラメータ回復は最初の試行では成功しない**ことです。

今回の実装でも、いくつかのバグを発見し修正しました。各コンポーネントを独立に検証してから統合する、という段階的アプローチが不可欠です。最終的に相対誤差1%未満でパラメータを回復できたとき、実装が正しいという確信を得ることができました。

## データ・設定・関数のパイプライン管理

複数のステップを連携させるパイプラインでは、**データ、設定、関数を一貫して管理する**仕組みが不可欠です。これは、パラメータ回復を成功させるための土台です。

### 設定をデータとして扱う

本プロジェクトの最も重要な設計原則は、**「設定をコードではなくデータとして扱う」**ことです。

従来のアプローチでは、パラメータをコード内にハードコードしていました。ソルバーで使ったパラメータを、シミュレーターでも、推定器でも、それぞれ書き直す——これでは、設定の不一致によるバグが頻発します。

本プロジェクトでは、以下のルールを徹底しました：

1. **すべてのパラメータを一箇所で定義**
   設定モジュールが唯一の真実の源（single source of truth）

2. **設定を結果と一緒に保存**
   ソルバーが設定をJSONファイルとして保存し、次のステップがそれを読み込む

3. **設定の整合性を自動検証**
   読み込んだ設定が現在のコードの設定と一致するかを確認。不一致があればエラー

この方法により、「シミュレーターが違うパラメータで動いていた」「推定器が間違った設定を使っていた」といったミスは原理的に発生しません。

### DRY原則：同じコードを二度書かない

**DRY（Don't Repeat Yourself）原則**も重要です。

例えば、報酬関数をソルバー、シミュレーター、推定器でそれぞれ実装すると、3箇所で同じコードが存在することになります。報酬関数を変更するとき、3箇所すべてを修正しなければならず、修正漏れがバグの原因になります。

本プロジェクトでは、**すべての関数を共有モジュールに集約**しました。報酬関数も、状態遷移も、可視化関数も、すべて1箇所にしか存在しません。変更は1箇所で済み、すべてのステップに自動的に反映されます。

この設計により、「ソルバーと推定器で報酬関数の定義が違っていた」というバグは原理的に発生しません。

### パイプラインの設計

データの流れは直線的です：

- **ソルバー** → 訓練済みモデル＋設定を保存
- **シミュレーター** → モデルと設定を読み込み、データ＋設定を保存
- **推定器** → データと設定を読み込み、パラメータを推定

各ステップは独立して実行可能で、前のステップの出力だけに依存します。この設計により、任意のステップを再実行でき、デバッグが容易になります。

## 実用的なアルゴリズム選択：完璧より機能を優先

推定器の実装では、重要な教訓を得ました。**理論的に洗練されたアルゴリズムが、必ずしも実用的とは限らない**のです。

### 試行錯誤の過程

3つのアルゴリズムを試しました：

1. **理論的に優雅な方法**：複雑すぎ、不安定 → **採用せず**
2. **理論的に正しい最適化**：数時間停止 → **採用せず**（研究イテレーションには遅すぎる）
3. **単純なグリッドサーチ**：10分で完了、可視化可能 → **採用**

### シンプルで機能する方が勝つ

AIに実装を依頼するとき、AIは「理論的に最も正しい」アプローチを提案しがちです。しかし、研究では**イテレーション速度**が重要です。

グリッドサーチは理論的には洗練されていませんが、以下の利点があります：
- 透明性：尤度曲面を完全に可視化できる
- 信頼性：大域最適が保証される
- 速度：低次元パラメータなら十分実用的

最適化は高次元パラメータでは必要ですが、低次元（1〜2次元）なら、グリッドサーチの方が研究には適しています。

この判断は、AIに任せるのではなく、**人間が研究の目的に照らして決める**べきです。

## 本番実行前の診断

高コストの計算を実行する前に、**小規模な診断を行う**ことが重要です。

### 診断ワークフロー

1. **小規模な検証を先に実行**
   真のパラメータ周辺で尤度を計算し、可視化

2. **視覚的チェック**
   - 尤度は滑らかか？
   - 最大値は真のパラメータにあるか？
   - 局所最適が存在するか？

3. **診断が問題なければ本番実行**
   全パラメータ範囲で推定

この診断により、本番実行前に重大な問題を発見できます。例えば、真のパラメータで尤度が最大にならなければ、シミュレーターか推定器にバグがあることがすぐに分かります。

今回の実装では、診断を経て最終的に相対誤差0.0%でパラメータを回復できました。これは、パイプライン全体が正しく実装されていることの証明です。


## 会話履歴の記録と学び

前回同様、AIとの会話履歴を詳細に記録し、[`docs/conversation/mdp_simulator_estimator_conversation_transcript.md`](../../conversation/mdp_simulator_estimator_conversation_transcript.md)として公開しています。

今回の会話履歴には、以下のような学びが含まれています：

- **「ファイルを作る」≠「内容を書く」**：ユーザーが明示的に「内容を書いて」と言うまで待つ
- **設定の不一致を早期に検出**：各ステップで設定を検証するコードの重要性
- **アルゴリズムの実用的選択**：理論的な洗練さより、実際に動くことを優先
- **診断の重要性**：本番実行前に小規模な検証を行う

会話履歴は、単なる記録以上の価値があります。なぜその選択をしたのか、どこでつまずいたのか、どうやって解決したのか——これらの情報は、同様のプロジェクトに取り組む際の貴重な参考資料になります。

また、会話履歴とGitコミット履歴を事後的にAIに評価させることで、自分の監督の仕方を改善できます。「この段階でもっと早く確認すべきだった」「この指示は曖昧すぎた」といったフィードバックを得ることができます。

## まとめ：パラメータ回復による最も包括的な検証

本実装事例は、**solve → simulate → estimate → recover** という完全な計算パイプラインをAIに実装させる方法論を示しました。

### 核心的な原則

1. **パラメータ回復は最も包括的な検証**
   単体テストや比較静学だけでは不十分。真のパラメータでデータを生成し、それを推定し、パラメータを回復できて初めて、実装が正しいと言える。

2. **設定をデータとして扱う**
   コードにハードコードせず、設定をJSONで保存し、各ステップで読み込んで検証する。設定の不一致を自動検出し、バグを防ぐ。

3. **DRY原則の徹底**
   同じコードを二度書かない。報酬関数、状態遷移、可視化——すべて共有モジュールに集約。一箇所の変更がすべてのステップに反映される。

4. **実用的なアルゴリズム選択**
   理論的な洗練さより、実際に動くことを優先。AIは「理論的に正しい」方法を提案するが、研究にはイテレーション速度が重要。

5. **診断的検証の重要性**
   高コストの本番実行前に、小規模な検証を行う。真のパラメータ周辺で尤度を計算し、可視化し、問題を早期発見する。

6. **会話履歴の記録**
   再現性のためだけでなく、ノウハウの共有と自己改善のツールとして。事後的にAIに評価させることで監督の仕方を改善できる。

### より複雑な問題への拡張

同じ方法論は、より複雑な問題にも適用できます。多次元パラメータ、異質性のあるエージェント、不完備情報、ゲーム理論的均衡——コンセプトは同じです。

solve → simulate → estimate → recoverのパイプラインを構築し、各ステップで設定と関数を共有し、最終的にパラメータ回復で検証する。この原則は、どのような計算経済学のプロジェクトにも適用できます。

### 実装の全公開

詳細な会話履歴、すべてのコード、レンダリングされたHTMLレポートは[GitHubリポジトリ](https://github.com/kohei-kawaguchi/TestAI)で公開しています。特に、[`docs/conversation/mdp_simulator_estimator_conversation_transcript.md`](../../conversation/mdp_simulator_estimator_conversation_transcript.md)には、完全な会話履歴と各段階での判断基準が記録されています。
